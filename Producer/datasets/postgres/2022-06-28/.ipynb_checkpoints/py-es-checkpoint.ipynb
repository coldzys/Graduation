{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "165c120b-29f9-4fb5-af19-d85b4f95ebe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from elasticsearch import Elasticsearch, helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6311424d-91a9-4a41-86f6-c7a324f3e0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def salary_check(salary: str):\n",
    "    if salary is None or salary.strip() == \"Cạnh tranh\" or salary.strip() == \"\":\n",
    "        return \"\"\n",
    "    salary = salary.replace(\"Trên\", \"\").replace(\"Dưới\", \"\").replace(\"Tr\", \"\").strip()\n",
    "    values = salary.split()\n",
    "    if len(values) == 2:\n",
    "        if values[1] == \"VND\":\n",
    "            return values[0].replace(',', '.')\n",
    "        if values[1] == \"USD\":\n",
    "            return float(values[0].replace(\",\", \"\")) * 23182 // 1000000\n",
    "    if len(values) == 4:\n",
    "        if values[3] == \"VND\":\n",
    "            return f\"{values[0].replace(',', '.')} - {values[2].replace(',', '.')}\"\n",
    "        if values[3] == \"USD\":\n",
    "            return f\"{float(values[0].replace(',', '')) * 23182 // 1000000} - {float(values[2].replace(',', '')) * 23182 // 1000000}\"\n",
    "\n",
    "\n",
    "def degree_check(bc):\n",
    "    if bc is None or bc == \"\" or bc.strip() == \"Khác\":\n",
    "        return \"Không yêu cầu\"\n",
    "    return bc.strip()\n",
    "\n",
    "\n",
    "def experience_check(kn: str):\n",
    "    if kn is None or kn == \"\" or kn.strip() == \"Chưa có kinh nghiệm\" or kn.strip() == \"0 - 0 Năm\":\n",
    "        return \"Không yêu cầu\"\n",
    "    kns = kn.replace(\"Năm\", \"\").strip().split()\n",
    "    if len(kns) == 2:\n",
    "        return kns[0]\n",
    "    if kns[0] >= kns[2]:\n",
    "        return kns[0]\n",
    "    else:\n",
    "        return f\"{kns[0]} - {kns[2]}\"\n",
    "\n",
    "\n",
    "def sex_check(sex: str):\n",
    "    if sex is None or sex == \"\":\n",
    "        return \"Không yêu cầu\"\n",
    "    return sex.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbc7bb45-3118-45e0-a5c4-9b9b59a54fbc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/07/03 12:38:00 WARN Utils: Your hostname, ubuntu resolves to a loopback address: 127.0.1.1; using 192.168.1.6 instead (on interface wlp7s0)\n",
      "22/07/03 12:38:00 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/fatcat2me/miniconda3/envs/student/lib/python3.8/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/07/03 12:38:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.config(\"spark.sql.debug.maxToStringFields\", 100000).getOrCreate()\n",
    "df = spark.read.json(\"careerbuilder-raw.json\").toPandas()\n",
    "df[\"update_time\"] = pd.to_datetime(df[\"update_time\"], format=\"%d/%m/%Y\").dt.strftime(\"%Y-%m-%d\")\n",
    "df[\"sex\"] = df[\"sex\"].apply(sex_check)\n",
    "df = df[df[\"company_name\"].str.strip() != \"\"]\n",
    "df[\"salary\"] = df[\"salary\"].apply(salary_check)\n",
    "df[\"degree\"] = df[\"degree\"].apply(degree_check)\n",
    "df[\"experience\"] = df[\"experience\"].apply(experience_check)\n",
    "df = spark.createDataFrame(df.astype(str)).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74962821-30d3-4a33-ab10-5386b2ad5125",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "es = Elasticsearch(\"http://172.18.0.19:9200\")\n",
    "\n",
    "\n",
    "def generator():\n",
    "    documents = []\n",
    "    for i in range(0, 5926):\n",
    "        document = {\n",
    "            \"id_\": i,\n",
    "            \"age\": df.iloc[i: i + 1].age, \n",
    "            \"company_name\": df.iloc[i: i + 1].company_name, \n",
    "            \"degree\": df.iloc[i: i + 1].degree, \n",
    "            \"experience\": df.iloc[i: i + 1].experience, \n",
    "            \"job_field\": df.iloc[i: i + 1].job_field, \n",
    "            \"job_name\": df.iloc[i: i + 1].job_name, \n",
    "            \"level\": df.iloc[i: i + 1].level, \n",
    "            \"location\": df.iloc[i: i + 1].location, \n",
    "            \"salary\": df.iloc[i: i + 1].salary, \n",
    "            \"sex\": df.iloc[i: i + 1].sex, \n",
    "            \"update_time\": df.iloc[i: i + 1].update_time, \n",
    "            \"working_form\": df.iloc[i: i + 1].working_form, \n",
    "        }\n",
    "        documents.append(document)\n",
    "    helpers.bulk(es, documents, index=\"job-careerbuilder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2f44ea1-daca-48d5-8b67-b11f2933db5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
